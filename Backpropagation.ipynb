{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Homework 13**\n",
        "\n",
        "For this assignment, we'll bring back some of the helper functions that we built throughout the semester:"
      ],
      "metadata": {
        "id": "ii4u0yu2oumG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywg4_gyBnjGv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Scaler():\n",
        "  def __init__(self,z):\n",
        "    self.min=np.min(z,axis=0)\n",
        "    self.max=np.max(z,axis=0)\n",
        "\n",
        "  def scale(self,x):\n",
        "\n",
        "    return (x-self.min)/(self.max-self.min+0.000001)\n",
        "\n",
        "  def unscale(self,x):\n",
        "    return x*(self.max-self.min+0.000001)+self.min\n",
        "\n",
        "def OneHot(y):\n",
        "  classes=np.max(y)+1\n",
        "  Y=np.zeros((len(y),classes))\n",
        "  i=np.arange(len(y))\n",
        "  Y[i,y[i]]=1\n",
        "  return Y\n",
        "\n",
        "def MSE(pred,y):\n",
        "  return np.mean((pred-y)**2)\n",
        "\n",
        "def Accuracy(pred,y):\n",
        "  '''Assumes pred is an array of probabilities, and y is a one-hot encoded target column'''\n",
        "  class_preds=np.argmax(pred,axis=1) #predicted classes from probabilities\n",
        "  class_target=np.argmax(y,axis=1) #target classes from OneHot encoding\n",
        "  return np.mean(class_preds==class_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our task now is to add `backprop` and `update` methods to the three classes you worked on in homework 12: `Linear()`, `Softmax()`, and `Model()`. There are no parameters to update and nothing to do with the gradients for the `Softmax` layer, so that is done for you:"
      ],
      "metadata": {
        "id": "tx6ZgzmcsI0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax():\n",
        "  '''Implement Softmax as final layer for prediction only'''\n",
        "  def predict(self,input):\n",
        "    return np.exp(input)/np.sum(np.exp(input),axis=1)[:,np.newaxis]\n",
        "    #the end part [:,np.newaxis] was added just to get the shape right for later use\n",
        "\n",
        "  def backprop(self,grad):\n",
        "    #We ignore this layer in backpropogation\n",
        "    return grad\n",
        "\n",
        "  def update(self,lr):\n",
        "    #Nothing to update\n",
        "    pass"
      ],
      "metadata": {
        "id": "9N0YtR1fsOOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For the `Linear` class, the `backprop` method will compute the gradient with respect to each parameter in that layer, given the gradients in the *next* layer. The method should output those gradients, for use in the *previous* layer.\n",
        "\n",
        "The `update` method of the `Linear` class should change the weights and biases, based on previously computed gradients and some learning rate."
      ],
      "metadata": {
        "id": "6TSw2p3vp4qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear():\n",
        "  '''Fully connected linear layer class'''\n",
        "  def __init__(self, input_size, output_size):\n",
        "    np.random.seed(input_size) #control randomness! Remove for real use\n",
        "    self.weights = np.random.randn(input_size, output_size) * np.sqrt(2.0 / input_size)\n",
        "    self.biases = np.zeros(output_size)\n",
        "\n",
        "  def predict(self,input):\n",
        "    self.input=input\n",
        "    return self.input@self.weights+self.biases\n",
        "\n",
        "  def backprop(self,grad):\n",
        "    self.grad=grad\n",
        "    return self.grad@(self.weights.transpose())\n",
        "\n",
        "  def update(self,lr):\n",
        "    wt_grad = (self.input.T)@(self.grad)\n",
        "    bias_grad = np.sum(self.grad, axis = 0)\n",
        "    self.weights -= lr * wt_grad / len(self.input)\n",
        "    self.biases -= lr * bias_grad / len(self.input)\n"
      ],
      "metadata": {
        "id": "5JxViaK9sVVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, add `backprop` and `update` methods to the `Model` class. The `backprop` method should pass the gradient of each layer (starting from the last) to the input of the `backprop` method for the previous layer. The `update` method should just call the `update` methods for each layer.\n",
        "\n",
        "Note that I have also included a `train` method that is very similar to what we have seen before, to implement batch gradient descent for the network. Make sure you read and understand that code!"
      ],
      "metadata": {
        "id": "tIcooQDouMQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "  def __init__(self,layerlist):\n",
        "    self.layerlist=layerlist\n",
        "\n",
        "  def add(self,layer):\n",
        "    self.layerlist+=[layer]\n",
        "\n",
        "  def predict(self,input):\n",
        "    for layer in self.layerlist:\n",
        "      input=layer.predict(input)\n",
        "    return input\n",
        "\n",
        "  def backprop(self,grad):\n",
        "    for layer in reversed(self.layerlist):\n",
        "      grad = layer.backprop(grad)\n",
        "    return input\n",
        "\n",
        "  def update(self,lr):\n",
        "    for layer in self.layerlist:\n",
        "      layer.update(lr)\n",
        "\n",
        "  def train(self,X,y,epochs,batch_size,lr,loss_fn):\n",
        "    n=len(X)\n",
        "    indices=np.arange(n)\n",
        "    for i in range(epochs):\n",
        "      np.random.seed(i)\n",
        "      np.random.shuffle(indices)\n",
        "      X_shuffle=X[indices]\n",
        "      y_shuffle=y[indices]\n",
        "      num_batches=n//batch_size\n",
        "      for j in range(num_batches):\n",
        "        X_batch=X_shuffle[j*batch_size:(j+1)*batch_size]\n",
        "        y_batch=y_shuffle[j*batch_size:(j+1)*batch_size]\n",
        "        pred=self.predict(X_batch)\n",
        "        lossgrad=pred-y_batch\n",
        "        #for regression, make sure shape of y_batch is (n,1)\n",
        "        #for Softmax classification, make sure y_batch is OneHot encoded\n",
        "        self.backprop(lossgrad)\n",
        "        self.update(lr)\n",
        "      if n%batch_size!=0: #Check if there is a smaller leftover batch\n",
        "        X_batch=X_shuffle[num_batches*batch_size:]\n",
        "        y_batch=y_shuffle[num_batches*batch_size:]\n",
        "        pred=self.predict(X_batch)\n",
        "        lossgrad=pred-y_batch\n",
        "        self.backprop(lossgrad)\n",
        "        self.update(lr)\n",
        "      if i%50==0: #Change this line to update reporting more/less frequently\n",
        "        print(\"epoch: \",i,\", loss: \",loss_fn(self.predict(X),y))\n"
      ],
      "metadata": {
        "id": "tGGSYCFJu_Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test your code on the good old iris dataset!\n",
        "\n",
        "Run this code block to import the dataset and define the feature matrix:"
      ],
      "metadata": {
        "id": "n54MjXh2u-dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "iris=pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv',index_col=0)\n",
        "\n",
        "X=np.array(iris.iloc[:,:4]) #All four flower trait features"
      ],
      "metadata": {
        "id": "bBFhtsEyyZh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we convert the target column (Species) to numerical values, and do a one-hot encoding:"
      ],
      "metadata": {
        "id": "-r1BbVEGYyx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flowerdict={'setosa':0,'versicolor':1,'virginica':2}\n",
        "target=iris['Species'].apply(lambda x:flowerdict[x])\n",
        "target=np.array(target)\n",
        "y=OneHot(target)"
      ],
      "metadata": {
        "id": "3SblRjpUy8Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model:"
      ],
      "metadata": {
        "id": "sFsv8uQaY5_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN=Model([])\n",
        "NN.add(Linear(4,4))\n",
        "NN.add(Linear(4,3))\n",
        "NN.add(Softmax())"
      ],
      "metadata": {
        "id": "piJlBfPfzxBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, if your code works, we can train the model, and report the accuracy as it improves:"
      ],
      "metadata": {
        "id": "FUsBmn08Y7_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN.train(X,y,500,50,0.01,Accuracy)"
      ],
      "metadata": {
        "id": "Um6Kkvp-z-aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c7dc0f-7456-4047-bdf1-b77bb04b341c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 , loss:  0.29333333333333333\n",
            "epoch:  50 , loss:  0.8533333333333334\n",
            "epoch:  100 , loss:  0.9\n",
            "epoch:  150 , loss:  0.9333333333333333\n",
            "epoch:  200 , loss:  0.94\n",
            "epoch:  250 , loss:  0.9466666666666667\n",
            "epoch:  300 , loss:  0.9466666666666667\n",
            "epoch:  350 , loss:  0.9533333333333334\n",
            "epoch:  400 , loss:  0.9533333333333334\n",
            "epoch:  450 , loss:  0.9533333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try a regression task. First we'll import a toy dataset:"
      ],
      "metadata": {
        "id": "HFEkqKIf3sPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mtcars=pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv',index_col=0)\n",
        "mtcars"
      ],
      "metadata": {
        "id": "Idxzrs3GdLsX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d312574-fd9d-4157-8c1a-8b6b4eb82d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
              "Mazda RX4            21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
              "Mazda RX4 Wag        21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
              "Datsun 710           22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
              "Hornet 4 Drive       21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
              "Hornet Sportabout    18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
              "Valiant              18.1    6  225.0  105  2.76  3.460  20.22   1   0     3   \n",
              "Duster 360           14.3    8  360.0  245  3.21  3.570  15.84   0   0     3   \n",
              "Merc 240D            24.4    4  146.7   62  3.69  3.190  20.00   1   0     4   \n",
              "Merc 230             22.8    4  140.8   95  3.92  3.150  22.90   1   0     4   \n",
              "Merc 280             19.2    6  167.6  123  3.92  3.440  18.30   1   0     4   \n",
              "Merc 280C            17.8    6  167.6  123  3.92  3.440  18.90   1   0     4   \n",
              "Merc 450SE           16.4    8  275.8  180  3.07  4.070  17.40   0   0     3   \n",
              "Merc 450SL           17.3    8  275.8  180  3.07  3.730  17.60   0   0     3   \n",
              "Merc 450SLC          15.2    8  275.8  180  3.07  3.780  18.00   0   0     3   \n",
              "Cadillac Fleetwood   10.4    8  472.0  205  2.93  5.250  17.98   0   0     3   \n",
              "Lincoln Continental  10.4    8  460.0  215  3.00  5.424  17.82   0   0     3   \n",
              "Chrysler Imperial    14.7    8  440.0  230  3.23  5.345  17.42   0   0     3   \n",
              "Fiat 128             32.4    4   78.7   66  4.08  2.200  19.47   1   1     4   \n",
              "Honda Civic          30.4    4   75.7   52  4.93  1.615  18.52   1   1     4   \n",
              "Toyota Corolla       33.9    4   71.1   65  4.22  1.835  19.90   1   1     4   \n",
              "Toyota Corona        21.5    4  120.1   97  3.70  2.465  20.01   1   0     3   \n",
              "Dodge Challenger     15.5    8  318.0  150  2.76  3.520  16.87   0   0     3   \n",
              "AMC Javelin          15.2    8  304.0  150  3.15  3.435  17.30   0   0     3   \n",
              "Camaro Z28           13.3    8  350.0  245  3.73  3.840  15.41   0   0     3   \n",
              "Pontiac Firebird     19.2    8  400.0  175  3.08  3.845  17.05   0   0     3   \n",
              "Fiat X1-9            27.3    4   79.0   66  4.08  1.935  18.90   1   1     4   \n",
              "Porsche 914-2        26.0    4  120.3   91  4.43  2.140  16.70   0   1     5   \n",
              "Lotus Europa         30.4    4   95.1  113  3.77  1.513  16.90   1   1     5   \n",
              "Ford Pantera L       15.8    8  351.0  264  4.22  3.170  14.50   0   1     5   \n",
              "Ferrari Dino         19.7    6  145.0  175  3.62  2.770  15.50   0   1     5   \n",
              "Maserati Bora        15.0    8  301.0  335  3.54  3.570  14.60   0   1     5   \n",
              "Volvo 142E           21.4    4  121.0  109  4.11  2.780  18.60   1   1     4   \n",
              "\n",
              "                     carb  \n",
              "Mazda RX4               4  \n",
              "Mazda RX4 Wag           4  \n",
              "Datsun 710              1  \n",
              "Hornet 4 Drive          1  \n",
              "Hornet Sportabout       2  \n",
              "Valiant                 1  \n",
              "Duster 360              4  \n",
              "Merc 240D               2  \n",
              "Merc 230                2  \n",
              "Merc 280                4  \n",
              "Merc 280C               4  \n",
              "Merc 450SE              3  \n",
              "Merc 450SL              3  \n",
              "Merc 450SLC             3  \n",
              "Cadillac Fleetwood      4  \n",
              "Lincoln Continental     4  \n",
              "Chrysler Imperial       4  \n",
              "Fiat 128                1  \n",
              "Honda Civic             2  \n",
              "Toyota Corolla          1  \n",
              "Toyota Corona           1  \n",
              "Dodge Challenger        2  \n",
              "AMC Javelin             2  \n",
              "Camaro Z28              4  \n",
              "Pontiac Firebird        2  \n",
              "Fiat X1-9               1  \n",
              "Porsche 914-2           2  \n",
              "Lotus Europa            2  \n",
              "Ford Pantera L          4  \n",
              "Ferrari Dino            6  \n",
              "Maserati Bora           8  \n",
              "Volvo 142E              2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc7b5a18-ea74-42af-91dc-7a63092637ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cyl</th>\n",
              "      <th>disp</th>\n",
              "      <th>hp</th>\n",
              "      <th>drat</th>\n",
              "      <th>wt</th>\n",
              "      <th>qsec</th>\n",
              "      <th>vs</th>\n",
              "      <th>am</th>\n",
              "      <th>gear</th>\n",
              "      <th>carb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mazda RX4</th>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.620</td>\n",
              "      <td>16.46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mazda RX4 Wag</th>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.875</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datsun 710</th>\n",
              "      <td>22.8</td>\n",
              "      <td>4</td>\n",
              "      <td>108.0</td>\n",
              "      <td>93</td>\n",
              "      <td>3.85</td>\n",
              "      <td>2.320</td>\n",
              "      <td>18.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hornet 4 Drive</th>\n",
              "      <td>21.4</td>\n",
              "      <td>6</td>\n",
              "      <td>258.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.08</td>\n",
              "      <td>3.215</td>\n",
              "      <td>19.44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hornet Sportabout</th>\n",
              "      <td>18.7</td>\n",
              "      <td>8</td>\n",
              "      <td>360.0</td>\n",
              "      <td>175</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.440</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Valiant</th>\n",
              "      <td>18.1</td>\n",
              "      <td>6</td>\n",
              "      <td>225.0</td>\n",
              "      <td>105</td>\n",
              "      <td>2.76</td>\n",
              "      <td>3.460</td>\n",
              "      <td>20.22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Duster 360</th>\n",
              "      <td>14.3</td>\n",
              "      <td>8</td>\n",
              "      <td>360.0</td>\n",
              "      <td>245</td>\n",
              "      <td>3.21</td>\n",
              "      <td>3.570</td>\n",
              "      <td>15.84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merc 240D</th>\n",
              "      <td>24.4</td>\n",
              "      <td>4</td>\n",
              "      <td>146.7</td>\n",
              "      <td>62</td>\n",
              "      <td>3.69</td>\n",
              "      <td>3.190</td>\n",
              "      <td>20.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merc 230</th>\n",
              "      <td>22.8</td>\n",
              "      <td>4</td>\n",
              "      <td>140.8</td>\n",
              "      <td>95</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.150</td>\n",
              "      <td>22.90</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merc 280</th>\n",
              "      <td>19.2</td>\n",
              "      <td>6</td>\n",
              "      <td>167.6</td>\n",
              "      <td>123</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.440</td>\n",
              "      <td>18.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merc 280C</th>\n",
              "      <td>17.8</td>\n",
              "      <td>6</td>\n",
              "      <td>167.6</td>\n",
              "      <td>123</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.440</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merc 450SE</th>\n",
              "      <td>16.4</td>\n",
              "      <td>8</td>\n",
              "      <td>275.8</td>\n",
              "      <td>180</td>\n",
              "      <td>3.07</td>\n",
              "      <td>4.070</td>\n",
              "      <td>17.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merc 450SL</th>\n",
              "      <td>17.3</td>\n",
              "      <td>8</td>\n",
              "      <td>275.8</td>\n",
              "      <td>180</td>\n",
              "      <td>3.07</td>\n",
              "      <td>3.730</td>\n",
              "      <td>17.60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Merc 450SLC</th>\n",
              "      <td>15.2</td>\n",
              "      <td>8</td>\n",
              "      <td>275.8</td>\n",
              "      <td>180</td>\n",
              "      <td>3.07</td>\n",
              "      <td>3.780</td>\n",
              "      <td>18.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cadillac Fleetwood</th>\n",
              "      <td>10.4</td>\n",
              "      <td>8</td>\n",
              "      <td>472.0</td>\n",
              "      <td>205</td>\n",
              "      <td>2.93</td>\n",
              "      <td>5.250</td>\n",
              "      <td>17.98</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lincoln Continental</th>\n",
              "      <td>10.4</td>\n",
              "      <td>8</td>\n",
              "      <td>460.0</td>\n",
              "      <td>215</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.424</td>\n",
              "      <td>17.82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chrysler Imperial</th>\n",
              "      <td>14.7</td>\n",
              "      <td>8</td>\n",
              "      <td>440.0</td>\n",
              "      <td>230</td>\n",
              "      <td>3.23</td>\n",
              "      <td>5.345</td>\n",
              "      <td>17.42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fiat 128</th>\n",
              "      <td>32.4</td>\n",
              "      <td>4</td>\n",
              "      <td>78.7</td>\n",
              "      <td>66</td>\n",
              "      <td>4.08</td>\n",
              "      <td>2.200</td>\n",
              "      <td>19.47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Honda Civic</th>\n",
              "      <td>30.4</td>\n",
              "      <td>4</td>\n",
              "      <td>75.7</td>\n",
              "      <td>52</td>\n",
              "      <td>4.93</td>\n",
              "      <td>1.615</td>\n",
              "      <td>18.52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Toyota Corolla</th>\n",
              "      <td>33.9</td>\n",
              "      <td>4</td>\n",
              "      <td>71.1</td>\n",
              "      <td>65</td>\n",
              "      <td>4.22</td>\n",
              "      <td>1.835</td>\n",
              "      <td>19.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Toyota Corona</th>\n",
              "      <td>21.5</td>\n",
              "      <td>4</td>\n",
              "      <td>120.1</td>\n",
              "      <td>97</td>\n",
              "      <td>3.70</td>\n",
              "      <td>2.465</td>\n",
              "      <td>20.01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dodge Challenger</th>\n",
              "      <td>15.5</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150</td>\n",
              "      <td>2.76</td>\n",
              "      <td>3.520</td>\n",
              "      <td>16.87</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMC Javelin</th>\n",
              "      <td>15.2</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.435</td>\n",
              "      <td>17.30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Camaro Z28</th>\n",
              "      <td>13.3</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>245</td>\n",
              "      <td>3.73</td>\n",
              "      <td>3.840</td>\n",
              "      <td>15.41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pontiac Firebird</th>\n",
              "      <td>19.2</td>\n",
              "      <td>8</td>\n",
              "      <td>400.0</td>\n",
              "      <td>175</td>\n",
              "      <td>3.08</td>\n",
              "      <td>3.845</td>\n",
              "      <td>17.05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fiat X1-9</th>\n",
              "      <td>27.3</td>\n",
              "      <td>4</td>\n",
              "      <td>79.0</td>\n",
              "      <td>66</td>\n",
              "      <td>4.08</td>\n",
              "      <td>1.935</td>\n",
              "      <td>18.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Porsche 914-2</th>\n",
              "      <td>26.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.3</td>\n",
              "      <td>91</td>\n",
              "      <td>4.43</td>\n",
              "      <td>2.140</td>\n",
              "      <td>16.70</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lotus Europa</th>\n",
              "      <td>30.4</td>\n",
              "      <td>4</td>\n",
              "      <td>95.1</td>\n",
              "      <td>113</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.513</td>\n",
              "      <td>16.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ford Pantera L</th>\n",
              "      <td>15.8</td>\n",
              "      <td>8</td>\n",
              "      <td>351.0</td>\n",
              "      <td>264</td>\n",
              "      <td>4.22</td>\n",
              "      <td>3.170</td>\n",
              "      <td>14.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ferrari Dino</th>\n",
              "      <td>19.7</td>\n",
              "      <td>6</td>\n",
              "      <td>145.0</td>\n",
              "      <td>175</td>\n",
              "      <td>3.62</td>\n",
              "      <td>2.770</td>\n",
              "      <td>15.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Maserati Bora</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>301.0</td>\n",
              "      <td>335</td>\n",
              "      <td>3.54</td>\n",
              "      <td>3.570</td>\n",
              "      <td>14.60</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volvo 142E</th>\n",
              "      <td>21.4</td>\n",
              "      <td>4</td>\n",
              "      <td>121.0</td>\n",
              "      <td>109</td>\n",
              "      <td>4.11</td>\n",
              "      <td>2.780</td>\n",
              "      <td>18.60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc7b5a18-ea74-42af-91dc-7a63092637ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc7b5a18-ea74-42af-91dc-7a63092637ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc7b5a18-ea74-42af-91dc-7a63092637ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Make the first column (mpg) the target array, `y`. Make sure `y` is a numpy array of shape (32,1).\n",
        "2.  Make the feature matrix `X` the remaining columns. Make sure `X` is a numpy array of shape (32,10)\n",
        "3. Scale both X and y to obtain X_scaled and y_scaled.\n",
        "4. Define a neural network called `mtNN` with two linear layers. The first layer should have 10 inputs and 10 outputs. The second layer should have 10 inputs and 1 output.\n",
        "5. Train your neural network on X_scaled and y_scaled. Use 500 epochs, a batch size of 5, a learning rate of 0.01, and the `MSE` function to report loss during training."
      ],
      "metadata": {
        "id": "YLMpB_8E31nK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = mtcars['mpg'][:,np.newaxis]\n",
        "X = np.array(mtcars.copy().drop(columns=['mpg']))\n",
        "sc = Scaler(X)\n",
        "scy = Scaler(y)\n",
        "X_scaled = sc.scale(X)\n",
        "y_scaled = scy.scale(y)\n",
        "\n",
        "mtNN=Model([])\n",
        "mtNN.add(Linear(10,10))\n",
        "mtNN.add(Linear(10,1))\n",
        "\n",
        "mtNN.train(X_scaled,y_scaled,500,5,0.01,MSE)"
      ],
      "metadata": {
        "id": "K1V2HYLX6Psz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4165f63e-ce64-4442-fe72-546d75dca4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-7502c70ba995>:1: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  y = mtcars['mpg'][:,np.newaxis]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 , loss:  0.6132212873141496\n",
            "epoch:  50 , loss:  0.04408313346974708\n",
            "epoch:  100 , loss:  0.025913084234521426\n",
            "epoch:  150 , loss:  0.018217787668791154\n",
            "epoch:  200 , loss:  0.014681871323904588\n",
            "epoch:  250 , loss:  0.01300060271038199\n",
            "epoch:  300 , loss:  0.012106862283319777\n",
            "epoch:  350 , loss:  0.011619894438197803\n",
            "epoch:  400 , loss:  0.011282488273086323\n",
            "epoch:  450 , loss:  0.011061247905031288\n"
          ]
        }
      ]
    }
  ]
}